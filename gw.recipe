##
## Title:        Gazeta Wyborcza Calibre Recipe
## Contact:      przemeq18@wp.pl
##
## License:      GNU General Public License v3 - http://www.gnu.org/copyleft/gpl.html
## Copyright:    przemeq18@wp.pl
##
## Written:      November 2011
## Last Edited:  2012-01-25
##

__license__     = 'GNU General Public License v3 - http://www.gnu.org/copyleft/gpl.html'
__copyright__   = 'przemeq18@wp.pl'

# Import the regular expressions module.
import re


from calibre.web.feeds.news import BasicNewsRecipe

class Gazeta_pl(BasicNewsRecipe):
    # Select / de-select the feeds you want in your ebook.
    #
    
    feeds = [ 
              (u'Wiadomo\u015bci \u015awiat', u'http://rss.feedsportal.com/c/32739/f/530270/index.rss'),
              (u'Wiadomo\u015bci Kraj', u'http://rss.feedsportal.com/c/32739/f/530266/index.rss'), 

	      (u'Krak\u00f3w', u'http://rss.feedsportal.com/c/32739/f/530324/index.rss'),

	      (u'Wyborcza.biz', u'http://gazeta.pl.feedsportal.com/c/32739/f/576250/index.rss'),
	      (u'Gospodarka', u'http://rss.feedsportal.com/c/32739/f/530278/index.rss'),

              (u'Nauka', u'http://rss.feedsportal.com/c/32739/f/530269/index.rss'),
	      (u'Technologie', u'http://gazeta.pl.feedsportal.com/c/32739/f/576336/index.rss'),      

	      (u'Komentarze', u'http://rss.feedsportal.com/c/32739/f/530312/index.rss'),
              (u'Opinie', u'http://rss.gazeta.pl/pub/rss/opinie.xml'),              
              #(u'Kultura', u'http://rss.gazeta.pl/pub/rss/gazetawyborcza_kultura.xml'),

              #(u'Du\u017cy Format', u'http://rss.feedsportal.com/c/32739/f/530265/index.rss'),
              #(u'Witamy w Polsce', u'http://rss.feedsportal.com/c/32739/f/530476/index.rss'),
              #(u'M\u0119ska Muzyka', u'http://rss.feedsportal.com/c/32739/f/530337/index.rss'),
              #(u'Lata Lec\u0105', u'http://rss.feedsportal.com/c/32739/f/530326/index.rss'),
              #(u'Solidarni z Tybetem', u'http://rss.feedsportal.com/c/32739/f/530461/index.rss'),
              #(u'W pon. - \u017bakowski', u'http://rss.feedsportal.com/c/32739/f/530491/index.rss'),
              #(u'We wt. - Kolenda-Zalewska', u'http://rss.feedsportal.com/c/32739/f/530310/index.rss'),
              #(u'\u015aroda w \u015brod\u0119', u'http://rss.feedsportal.com/c/32739/f/530428/index.rss'),
              #(u'W pi\u0105tek - Olejnik', u'http://rss.feedsportal.com/c/32739/f/530364/index.rss'),
              #(u'Nekrologi', u'http://rss.feedsportal.com/c/32739/f/530358/index.rss')
            ]


    #    **** SELECT YOUR USER PREFERENCES ****

    # Title to use for the ebook.
    #
    title = u'Gazeta Wyborcza'

    # A brief description for the ebook.
    #
    description = u'Gazeta Wyborcza - wiadomo\u015bci'

    # The max number of articles which may be downloaded from each feed.
    # I've never seen more than about 70 articles in a single feed in the
    # BBC feeds.
    #
    max_articles_per_feed = 30

    # The max age of articles which may be downloaded from each feed. This is
    # specified in days - note fractions of days are allowed, Eg. 2.5 (2 and a
    # half days). My default of 1.5 days is the last 36 hours, the point at
    # which I've decided 'news' becomes 'old news', but be warned this is not
    # so good for the blogs, technology, magazine, etc., and sports feeds.
    # You may wish to extend this to 2-5 but watch out ebook creation time will
    # increase as well. Setting this to 30 will get everything (AFAICT) as long
    # as max_articles_per_feed remains set high (except for 'Click' which is
    # v. low volume and its currently oldest article is 4th Feb 2011).
    #
    oldest_article = 1.2

    # Number of simultaneous downloads. 20 is consistantly working fine on the
    # BBC News feeds with no problems. Speeds things up from the defualt of 5.
    # If you have a lot of feeds and/or have increased oldest_article above 2
    # then you may wish to try increasing simultaneous_downloads to 25-30,
    # Or, of course, if you are in a hurry. [I've not tried beyond 20.]
    #
    simultaneous_downloads = 5

    # Timeout for fetching files from the server in seconds. The default of
    # 120 seconds, seems somewhat excessive.
    #
    timeout = 120

    # The format string for the date shown on the ebook's first page.
    # List of all values: http://docs.python.org/library/time.html
    # Default in news.py has a leading space so that's mirrored here.
    # As with 'feeds' select/de-select by adding/removing the initial '#',
    # only one timefmt should be selected, here's a few to choose from.
    #
    timefmt = ' [%a, %Y %b %d]'
    #timefmt = ' [%a, %d %b %Y]'              # [Fri, 14 Nov 2011] (Calibre default)
    #timefmt = ' [%a, %d %b %Y %H:%M]'       # [Fri, 14 Nov 2011 18:30]
    #timefmt = ' [%a, %d %b %Y %I:%M %p]'    # [Fri, 14 Nov 2011 06:30 PM]
    #timefmt = ' [%d %b %Y]'                 # [14 Nov 2011]
    #timefmt = ' [%d %b %Y %H:%M]'           # [14 Nov 2011 18.30]
    #timefmt = ' [%Y-%m-%d]'                 # [2011-11-14]
    #timefmt = ' [%Y-%m-%d-%H-%M]'           # [2011-11-14-18-30]

    # Author of this recipe.
    __author__ = 'przemeq'

    language = 'pl_PL'

    cover_url = 'http://bi.gazeta.pl/im/8/5415/m5415058.gif'

    # Set tags.
    tags = 'news'

    # Set publisher and publication type.
    publisher = 'Agora'
    publication_type = 'newspaper'

    encoding = 'iso-8859-2'

    use_embedded_content = False

    remove_empty_feeds = True

    remove_javascript = True

    no_stylesheets = True

    extra_css = ''

    keep_only_tags = [
      dict(name='div',  attrs={'id':'article'})
    ]

    def skip_ad_pages(self, soup):
        tag = soup.find(name='a', attrs={'class':'btn'})
        if tag:        
            return self.index_to_soup(self.print_version(tag['href']), raw=True)


    def print_version(self, url):
        url = re.sub('0C10H', '0C20A290A20A0H', url)
        url = re.sub('\/1,', '/2029020,', url)
        return url
